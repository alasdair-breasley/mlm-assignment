---
title: "Title of your report"
author: "fmcv76"
date: "01/03/24"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE)

```

## Initial Data Loading and Checks 

```{r include = FALSE}

library(lme4)
library(lmerTest)
library(performance)
library(ggplot2)
library(scales)
library(sjPlot)
library(tidyverse)
library(tinytex)
library(wordcountaddin)

```

```{r}

# Load data 
crt_data = read.csv("https://andygolightly.github.io/teaching/MATH43515/CRT.csv", 
                    header = TRUE)

# Preprocess data 
crt_data = crt_data %>% 
  dplyr::rename(Class = class) %>% 
  dplyr::mutate(Pupil = as.factor(Pupil),
                School = as.factor(School),
                Intervention = as.factor(Intervention),
                FSM = as.factor(FSM),
                Class = as.factor(Class))

# Check for NAs 
colSums(is.na(crt_data))

```

## Introduction 

- Randomised Control Trials (RCTs) are used to assess the effectiveness of an intervention. Individuals are randomly assigned to either the treatment or control group and this aims to prevent systematic differences between intervention groups with regards to both observables and unobservables, preventing selection into treatment bias. 
- In an educational setting, it may be neither practical nor ethical to administer an intervention at the Pupil or Class level. Providing an intervention at the Pupil level may not be practical or ethical given it would be practically challenging and could be seen as immoral for a teacher to provide some Pupils within a single Class with an intervention and not others. Providing an intervention at the Class level may be more practical than at the Pupil level but may still not be ethical as it could be seen as immoral for a School to provide Pupils in one Class with an intervention and not others. 
- This is where Cluster Randomised Control Trials (CRCTs) are useful. A CRCT in an educational setting can allow for an intervention to be administered at the School level, with less practical and ethical issues. Schools are randomly assigned to either the treatment or control group. 
- This report will assess the results of a 3-level educational CRCT. 20 Schools were randomly assigned to either the control or treatment group, with the treatment group receiving an educational intervention to try and improve Pupils test performance. Pupils test scores were calculated for 2 Classes per School, with test scores calculated both pre and post educational intervention. It is not clear how the initial 20 Schools were selected from the wider population of Schools in the country so there may be selection into experiment bias present. It appears that some Schools and Pupils dropped out of the study so there may be selection into observation bias present, with evidence of this being the absence of School IDs 18 and 19, and Pupil IDs 256, 257 and 258. 
- The variables collected as part of the CRCT were:
  - __Pupil__ - Anonymised Pupil ID. 
  - __Class__ - Anonymised Class ID. 
  - __School__ - Anonymised School ID. 
  - __Intervention__ - Flag indicating whether a Pupil is in the control or treatment. 
  - __FSM__ - Flag indicating whether a Pupil is eligible for free school meals. 
  - __Pretest__ - A pre-intervention test score for each Pupil. 
  - __Posttest__ - A post-intervention test score for each Pupil. 

__Summary Statistics__

```{r echo = FALSE}

# Summary statistics 
crt_data %>% 
  dplyr::select(-c(Pupil, Class)) %>% 
  dplyr::select(School, Intervention, FSM, Pretest, Posttest) %>% 
  summary()

```

__Pupils per School__

```{r echo = FALSE}

pps_df = as.data.frame(table(crt_data$School))

names(pps_df) = c("School", "Pupils")

print(pps_df, row.names = FALSE)

```

Note: There are no Pupils for Schools 18 or 19. 

```{r echo = FALSE}

# Distribution of Pretest scores by intervention group histogram 
ggplot(data = crt_data, aes(x = Pretest, fill = Intervention)) +
  geom_histogram(aes(y = after_stat(count)), binwidth = 1, colour = "black", position = "identity", alpha = 0.3) +
  scale_fill_manual(values = c("1" = "red", "0" = "blue"), labels = c("1" = "Treatment Group", "0" = "Control Group"), guide_legend(title = "")) +
  scale_x_continuous(breaks = breaks_width(1), minor_breaks = NULL) +
  scale_y_continuous(breaks = breaks_width(10)) +
  labs(x = "Pretest Scores", y = "Count", title = "Distribution of Pretest Scores Overlaid by Intervention Group") +
  theme(panel.border = element_rect(colour = "black", fill = NA, linewidth = 0.5), axis.text = element_text(color = "black", size = 10),
        axis.title = element_text(size = 12), plot.title = element_text(size = 12, face = "bold"))

```

- There is a similar distribution of Pretest scores for both the control and treatment groups with slightly more Pupils in the treatment group. 

```{r echo = FALSE}

# Distribution of Posttest scores by intervention group histogram 
ggplot(data = crt_data, aes(x = Posttest, fill = Intervention)) +
  geom_histogram(aes(y = after_stat(count)), binwidth = 4, colour = "black", position = "identity", alpha = 0.3) +
  scale_fill_manual(values = c("1" = "red", "0" = "blue"), labels = c("1" = "Treatment Group", "0" = "Control Group"), guide_legend(title = "")) +
  scale_x_continuous(breaks = breaks_width(4), minor_breaks = NULL) +
  scale_y_continuous(breaks = breaks_width(10)) +
  labs(x = "Posttest Scores", y = "Count", title = "Distribution of Posttest Scores Overlaid by Intervention Group") +
  theme(panel.border = element_rect(colour = "black", fill = NA, linewidth = 0.5), axis.text = element_text(color = "black", size = 10),
        axis.title = element_text(size = 12), plot.title = element_text(size = 12, face = "bold"))

```

- Posttest scores are higher across both the control and treatment group. The distribution of Posttest scores for the treatment group appears to be shifted to the right with higher scores on average and no longer follows a similar distribution to the control group (like Pretest). 

```{r echo = FALSE}

pvp_cor = round(cor(crt_data$Pretest, crt_data$Posttest, method = "spearman"), 2)

# Pretest scores vs Postest scores scatter plot 
ggplot(crt_data, aes(x = Pretest, y = Posttest, colour = Intervention)) +
  geom_point(size = 1.5, alpha = 0.5, position = position_jitter(width = 0.2, height = 0.2)) +
  scale_colour_manual(values = c("1" = "red", "0" = "blue"), labels = c("1" = "Treatment Group", "0" = "Control Group"), guide_legend(title = "")) +
  geom_smooth(formula = y ~ x, method = "lm", color = "black", se = TRUE) +
  scale_x_continuous(breaks = breaks_width(1)) +
  scale_y_continuous(breaks = breaks_width(2)) +
  labs(x = "Pretest Score", y = "Posttest Score", title = "Pretest Scores vs Posttest Scores") +
  theme(panel.border = element_rect(colour = "black", fill = NA, linewidth = 0.5), axis.text = element_text(color = "black", size = 10),
        axis.title = element_text(size = 12), plot.title = element_text(size = 12, face = "bold"))

```

- Naive analysis at the Pupil level. 
- Note: Points at jittered in both the x and y direction to improve visibility. 
- Grey area represents the 95% confidence interval. 
- There is a moderate positive Spearman's correlation of `r pvp_cor` between Pretest and Posttest scores. Spearman's was used as Pretest does not appear to be normally distributed. 

## Methods 

- Multilevel models help solve the problem when analysing hierarchical data of lower-level-units belonging to the same upper-level-item being correlated. Multilevel models are appropriate for use in this case given the hierarchical structure of the data collected from the 3-level CRCT and the cluster randomisation used. In this context multilevel models can provide more accurate estimates of treatment effects than models which ignore the hierarchical data structure by accounting for the correlation within clusters (intra-class correlation). 
- The 3-level structure of the data is as follows: Pupils nested within Classes nested within Schools. 
- The covariates at the Pupil level are: FSM and Pretest. 
- There are no covariates at the Class level. 
- The covariate at the School level is: Intervention. 

\newpage

## Analysis 

__2-Level Intercept-Only Model for School__

```{r}

# Fit intercept-only model for school 
school_intercept_only_model = lmer(formula = Posttest ~ 1 + (1 | School), data = crt_data)

summary(school_intercept_only_model)

# Calculate ICC 
icc(school_intercept_only_model)

```

- Intra-Class Correlation value of 0.244, and therefore 24.4% of the variation in Posttest scores can be explained by the School grouping structure. This is a relatively large ICC value in an educational setting and therefore the School grouping structure should be included in modelling. 

 __3-Level Intercept-Only Model for School and Class__ 

```{r}

# Fit intercept-only model for classes nested within schools 
school_class_intercept_only_model = lmer(formula = Posttest ~ 1 + (1 | School) + (1 | School : Class), data = crt_data)

summary(school_class_intercept_only_model)

# Calculate ICC 
icc(school_class_intercept_only_model)

```

- Only a very small increase in ICC to 0.258 when adding Classes nested within Schools to the Intercept-Only Model, with 25.8% of the variation in Posttest scores explained by the Classes nested within Schools grouping structure. This relatively small increase in ICC, plus Schools only having 2 Classes per School (not robust to estimate the variance between Classes with so few data points) indicates that the Classes nested within Schools grouping structure should not be included in modelling. 

__Manually Calculating ICC and VPC Values__

```{r}

# Extract summary of variances 
var_summary = as.data.frame(VarCorr(school_class_intercept_only_model))

sig = var_summary$vcov[3]  # Residual variance 

sigv = var_summary$vcov[2] # RE variance for school 

sigu = var_summary$vcov[1] # RE variance for class 

totalvar = sum(var_summary$vcov) #total variance 

vpc_school = round(100 * sigv / totalvar, 2)

vpc_class = round(100 * sigu / totalvar, 2)

icc_school = round(100 * sigv / totalvar, 2)

icc_class = round(100 * (sigu + sigv) / totalvar, 2)

```

- There is a `r vpc_class`% response variation at the Class level and `r vpc_school`% at the School level. Variability between Schools is much more than between classes. The ICC for Class is `r icc_class`%, largely driven by the School level ICC of `r icc_school`%. Not sure exactly why ICC for 2-Level Intercept-Only Model above is different to icc_school here - because it didn't take into account Class hierarchy and some of the variance between Schools captured was actually the variance between Classes within Schools?

__2-Level Random Intercept Model for School with Pupil Level Covariates__

```{r}

# Fit random intercept model for school with pupil level covariates 
random_intercept_pupilcovs_model = lmer(formula = Posttest ~ 1 + Pretest + FSM + (1 | School), data = crt_data)

summary(random_intercept_pupilcovs_model)

```

- Pretest is statistically significant. 
- FSM is not statistically significant. 

__2-Level Random Intercept Model for School with Pretest Pupil Level Covariate__

```{r}

# Fit random intercept model for school with Pretest 
random_intercept_Pretest_model = lmer(formula = Posttest ~ 1 + Pretest + (1 | School), data = crt_data)

summary(random_intercept_Pretest_model)

```

__Comparison of 2-Level Intercept-Only Model for School with 2-Level Random Intercept Model for School with Pretest Pupil Level Covariate__

- Test the null hypothesis that $b_1=0$ and $b_{2}=0$ against an alternative that at least one of these fixed effects of Pretest and FSM is not 0. 

```{r}

anova(school_intercept_only_model, random_intercept_Pretest_model)

```

- The null hypothesis is rejected and Pretest is needed. 

__Comparison of 2-Level Random Intercept Model for School with Pretest Pupil Level Covariate with 2-Level Random Intercept Model for School with Pupil Level Covariates__

```{r}

anova(random_intercept_Pretest_model, random_intercept_pupilcovs_model)

```

- There is only a small reduction in deviance when adding FSM and there is insufficient evidence against the null hypothesis that the fixed effect of FSM is zero. The null hypothesis is therefore retained and FSM is not needed. 

__2-Level Random Intercept Model for School with Pretest Pupil Level Covariate and Intervention School Level Covariate__

```{r}

# Fit random intercept model for school with Pretest and Intervention 
random_intercept_Pretest_Intervention_model = lmer(formula = Posttest ~ 1 + Pretest + Intervention + (1 | School), data = crt_data)

summary(random_intercept_Pretest_Intervention_model)

```

- Pretest is statistically significant. 
- Intervention is statistically significant. 

__2-Level Random Intercept Model for School with Pretest Pupil Level Covariate (Both Fixed Effect and Random Slope) and Intervention School Level Covariate__

```{r}

# Fit random intercept model for school with Pretest (both fixed effect and random slope) and Intervention 
random_intercept_Pretest_slope_Intervention_model = lmer(formula = Posttest ~ 1 + Pretest + Intervention + (1 + Pretest | School), data = crt_data)

summary(random_intercept_Pretest_slope_Intervention_model)

```

- Test the null hypothesis that the random slope for Pretest is zero. 

```{r}

ranova(random_intercept_Pretest_slope_Intervention_model)

```

- The null hypothesis is retained and the random slope for Pretest is not needed. 

__2-Level Random Intercept Model for School with Pretest Pupil Level Covariate and Intervention School Level Covariate (Both Fixed Effect and Random Slope)__

```{r}

# Fit random intercept model for school with Pretest and Intervention (both fixed effect and random slope) 
random_intercept_Pretest_Intervention_slope_model = lmer(formula = Posttest ~ 1 + Pretest + Intervention + (1 + Intervention | School), data = crt_data, control = lmerControl(optimizer = "Nelder_Mead"))

summary(random_intercept_Pretest_Intervention_slope_model)

```

- Using better optimiser. 
- Singularity issue. 

- Test the null hypothesis that the random slope for Intervention is zero. 

```{r}

ranova(random_intercept_Pretest_Intervention_slope_model)

```

- The null hypothesis is retained and the random slope for Intervention is not needed. 

__Model Diagnostics__

```{r}

plot(random_intercept_Pretest_Intervention_model)

```

- __Linearity Assumption__ - Points spread roughly evenly above and below the 0 line with no obvious pattern, therefore the assumption of a linear relationship between predictor variables and the response variable plausibly holds. 
- __Homoscedasticity Assumption__ - There is not an obvious change in spread for the residuals over the range of fitted values, therefore the assumption of residuals having constant variance across different values of the response variable plausibly holds. 

```{r}

residuals_1_to_n_minus_1 = residuals(random_intercept_Pretest_Intervention_model)[1:(length(residuals(random_intercept_Pretest_Intervention_model)) - 1)]

residuals_2_to_n = residuals(random_intercept_Pretest_Intervention_model)[2:length(residuals(random_intercept_Pretest_Intervention_model))]

plot(residuals_1_to_n_minus_1, residuals_2_to_n)

cor(residuals_1_to_n_minus_1, residuals_2_to_n)

```

- __Independence Assumption__ - The Pearson's correlation between the first 259 residuals (all except the last) and the last 259 residuals (all except the first) is low, therefore the assumption of indepentent residuals plausibly holds. 

```{r}

qqnorm(resid(random_intercept_Pretest_Intervention_model))

qqline(resid(random_intercept_Pretest_Intervention_model), col = "red") 

```

- __Normality Assumption - Residuals__ - The residuals mostly fit well with the theoretical quantiles of a normal distribution with only a slight deviation at each tail, therefore the assumption of normally distributed residuals plausibly holds. 

```{r}

qqnorm(ranef(random_intercept_Pretest_Intervention_model)$School[, 1])

qqline(ranef(random_intercept_Pretest_Intervention_model)$School[, 1], col = "red")

```

- __Normality Assumption - Random Effects__ - The random effects for School mostly fit well with the theoretical quantiles of a normal distribution with a small deviation at each tail, therefore the assumption of normally distributed random effects plausibly holds. 

## Word Count

```{r warning = FALSE, include = FALSE}

n_words = paste0("Word Count: ", as.character(word_count()))

```

```{r echo = FALSE}

print(n_words)

```
